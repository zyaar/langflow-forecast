from typing import List
from pandas.errors import ParserError
import pandas as pd
import numpy as np
from langflow.schema.dataframe import DataFrame

from langflow.base.forecasting_common.constants import FORECAST_INT_TO_SHORT_MONTH_NAME, ForecastModelInputTypes, ForecastModelTimescale
from langflow.base.forecasting_common.models.date_utils import gen_dates


# FORECAST SPECIFIC IMPORTS
# =========================


# COMPONENT SPECIFIC IMPORTS
# ==========================
from datetime import datetime


# CONSTANTS
# =========



# CLASSES
# =======

# ForecastDataModel
# A single static class which centralizes all functions necessary to ensure that a Langflow DataFrame (which inherits from Pandas Dataframe) has everything necessary
# to work as our ForecastDataModel
class ForecastDataModel(DataFrame):
      RESERVED_COLUMN_INDEX_NAME = "dates" # name of the dates column for the forecasting model.  This must be a unique column
      #EDITABLE_VALUES_TOKEN = np.NAN # the value to enter in the data model for cells which will be updated after the model build
      EDITABLE_VALUES_TOKEN = 0.0 # the value to enter in the data model for cells which will be updated after the model build

      REQ_FORECAST_MODEL_ATTR_NAMES = ["start_year", "num_years", "input_type", "start_month", "timescale"]
      REQ_FORECAST_MODEL_ATTR_TYPES = [int, int, ForecastModelInputTypes, int, ForecastModelTimescale]
      REQ_FORECAST_MODEL_ATTR_DISPLAY_NAMES = ["Start Year", "Number of Years", "Input Type", "Start Month", "Time-scale"]



      # FUNCTIONS
      # =========
      @staticmethod
      def generate_empty_forecast_data_model(
            start_year: int,
            num_years: int,
            input_type: 'ForecastModelInputTypes',
            start_month: int,
            timescale: ForecastModelTimescale.MONTH,                  
      ) -> DataFrame:
            
            # since there are already a lot of different methods built to create a data forecast, we're going to leverage them for convenience instead of creating yet another one,
            # we'll create a single row forecast will all zeros for values and then delete the row
            length_of_series = len(ForecastDataModel.gen_forecast_dates(start_year = start_year, start_month = start_month, num_years = num_years, timescale = timescale))
            blank_series = [ForecastDataModel.EDITABLE_VALUES_TOKEN] * length_of_series
            
            forecast_dataframe = ForecastDataModel.init_forecast_data_model_single_series(
                  data=blank_series,
                  start_year = start_year,
                  start_month = start_month,
                  num_years = num_years,
                  input_type = input_type,
                  timescale = timescale,
            )

            return forecast_dataframe.drop(forecast_dataframe.columns[-1], axis=1)

      

      # init_forecast_data_model_single_series
      # The simplest way to create a Data Forecast Model.  Give it one series od data (ints or floats)Given a list of ints or floats for the first series, creates a Forecast Data Model compliant dataframe by generating the dates, adding the 
      # specific meta-data attributes and data structures to work as the basis of the forecast
      #  
      # INPUTS:
      #     data - a list of int or floats (first series)
      #     start_year - the start year for the forecast
      #     num_years - number of years for the forecast
      #     input_type - is the forecast type a 'Time Based Input' or 'Single Input' (may be an issue if there are both of them)
      #     start_month - 
      # 
      # OUTPUTS:
      #   DataFrame

      @staticmethod
      def init_forecast_data_model_single_series(
            data: List[int|float],
            start_year: int,
            num_years: int,
            input_type: 'ForecastModelInputTypes',
            start_month: int,
            timescale: ForecastModelTimescale,
            series_name: str="",
      ) -> DataFrame:
            
            # create a dates for this time series based on input values
            time_series_dates = ForecastDataModel.gen_forecast_dates(start_year = start_year, start_month = start_month, num_years = num_years, timescale = timescale)

            # bundle it and the series into a dictionary of series and create a DataFrame
            forecast_model = DataFrame(data={ForecastDataModel.RESERVED_COLUMN_INDEX_NAME: time_series_dates, series_name: data})

            # return with the Forecast variables added
            return ForecastDataModel.init_forecast_data_model(forecast_model,
                                                              start_year=start_year,
                                                              num_years=num_years,
                                                              input_type=input_type,
                                                              start_month=start_month,
                                                              timescale=timescale)


      # init_forecast_data_model
      # Add the ForecastDataModel specific meta-data attributes and data structures to a generic DataFrame in order for it to work as the basis of the forecast
      #  
      # INPUTS:
      #     data - the dataframe which will used as the basis
      #     start_year - the start year for the forecast
      #     num_years - number of years for the forecast
      #     input_type - is the forecast type a 'Time Based Input' or 'Single Input' (may be an issue if there are both of them)
      #     start_month - 
      # 
      # OUTPUTS:
      #   DataFrame df

      @staticmethod
      def init_forecast_data_model(
            data: DataFrame,
            start_year: int,
            num_years: int,
            input_type: 'ForecastModelInputTypes',
            start_month: int,
            timescale: ForecastModelTimescale,
      ) -> DataFrame:
            df = data.copy()

            # if it's not already a dataframe, then create a dataframe
            if(not isinstance(df, DataFrame)):
                  df = DataFrame(data=df)

            # fix any index situation
            df = ForecastDataModel.fix_index_issues(df)

            # set-up the additional forecasting-specific attributes inside pandas attributes (where they should be preserved)
            df.attrs["start_year"] = start_year
            df.attrs["num_years"] = num_years
            df.attrs["input_type"] = input_type
            df.attrs["start_month"] = start_month
            df.attrs["timescale"] = timescale

            return(df)

      

      # convert_dfs_to_forecast_models
      # Takes a list of dfs or DataFrames and fixes some so that they can be used as forecast models
      #  
      # INPUTS:
      #     datas - The list of dataframes that will be used
      # 
      # OUTPUTS:
      #   List of DataFrame dfs which is Forecast Model compliant

      @staticmethod
      def convert_dfs_to_forecast_models(datas: List[DataFrame]) -> List[DataFrame]:
            return([ForecastDataModel.convert_df_to_forecast_model(df) for df in datas])
            

      # convert_df_to_forecast_model
      # Langflow DataFrames seem to arbitrarily convert dates types into strings and Enum types to ints, this function converts them back.
      # Should be called before working with any DataFrames which need to be treated as Forecast Models/
      #  
      # INPUTS:
      #     data - the dataframe which will used as the basis
      # 
      # OUTPUTS:
      #   DataFrame df which is Forecast Model compliant

      @staticmethod
      def convert_df_to_forecast_model(data: DataFrame) -> DataFrame:

           # fix any index issues that may be around
            df = ForecastDataModel.fix_index_issues(data)

            # check all pd attrs to make sure they are there and cast them
            df.attrs["input_type"] = ForecastModelInputTypes(df.attrs["input_type"])
            df.attrs["timescale"] = ForecastModelTimescale(df.attrs["timescale"])

            return(df)
      

      # add_col_to_model
      # Add a new column to the data_model
      #  
      # INPUTS:
      #     data - the dataframe which will used as the basis
      #     new_col_values - list of floating points
      #     new_col_prefix - prefix to add to the unique id to indicate the function
      # 
      # OUTPUTS:
      #   DataFrame df which is Forecast Model compliant

      @staticmethod
      def add_col_to_model(data: DataFrame, new_col_values: List[float], new_col_name = "unnamed row") -> DataFrame:
            # fix any index issues that may be around
            df = ForecastDataModel.fix_index_issues(data)
            df_new = pd.concat([df, pd.Series(new_col_values, name=new_col_name)], axis=1)
            
            if(not ForecastDataModel.is_valid_forecast_data_model(df_new)):
                  raise ValueError(f"add_col_to_model:  Error, invalid forecast data model\n{df_new}")
            
            return(df_new)


      # concat_and_sum
      # Merge all the dataframes together (unique columns only) and add a new column to the data_model
      # with the sum of all the totals from all the dataframes
      #  
      # INPUTS:
      #     data - list of dataframe whose values will be added together
      #     new_col_name - the unique name for the column
      #     skip_total_is_one - boolean value, if true, do NOT create a totals column if only one dataframe in the list
      # 
      # OUTPUTS:
      #   DataFrame df which is Forecast Model compliant

      @staticmethod
      def concat_and_sum(datas: List[DataFrame], new_col_name = "Total", skip_total_if_one = True) -> DataFrame:
            # list of totals ids
            totals_ids = []

            # if skip_total_if_one is true and there is only one dataframe provided, do the validation check, but then
            # return the original dataframe without a totals column
            if(skip_total_if_one and len(datas) < 2):
                  # Before checking the input parameters, check that the current data set is a valid Forecasting Model
                  (is_valid, err_msg) = ForecastDataModel.is_valid_forecast_data_model(datas[0])
                  
                  if(is_valid == False):
                        raise ValueError(f"Unable to combine forecast models.  In the list of inputs, #1 is not a valid forecast model: {err_msg}")
                  
                  return(datas[0])

                  
            # run the validation loop against all data sets to ensure they are valid, and grab the ids from
            # the last (i.e. total line) of each one
            for i in range(len(datas)):
                  summed_cols = []

                  # Before checking the input parameters, check that the current data set is a valid Forecasting Model
                  (is_valid, err_msg) = ForecastDataModel.is_valid_forecast_data_model(datas[i])
                  
                  if(is_valid == False):
                        raise ValueError(f"Unable to combine forecast models.  In the list of inputs, #{i+1} is not a valid forecast model: {err_msg}")
                  
                  # grab the last rightmost column (defined as the totals column) and put in a common dataframe
                  totals_ids.append(datas[i].iloc[:, -1].name)
                  
                  # if second or later dataset, concat with first, but only add columns not found in first
                  if(i == 0):
                        combined_df = datas[i].copy()
                  else:
                        new_cols = list(set(datas[i].columns).difference(combined_df.columns))
                        combined_df = pd.concat([combined_df, datas[i][new_cols]], axis=1)

            # create the totals column
            combined_df = ForecastDataModel.add_col_to_model(data = combined_df,
                                                             new_col_values= [0] * len(combined_df.index),
                                                             new_col_name = new_col_name)
            
            if(not ForecastDataModel.is_valid_forecast_data_model(combined_df)):
                  raise ValueError(f"sum_cols_add_total_to_model:  Error, new combined model is invalid forecast data model\n{combined_df}")
            
            return(combined_df)


            # # if only one forecast model provided
            # if(len(datas) == 1):
            #       (is_valid, err_msg) = ForecastDataModel.is_valid_forecast_data_model(datas[0])

            #       if(not is_valid):
            #             raise ValueError(f"Unable to sum forecast models.  In the list of inputs, #1 is not a valid forecast model: {err_msg}")
                  
            #       return(datas[0])
            
            # # fix any index issues that may be around
            # df = ForecastDataModel.fix_index_issues(data)
            # df_new = pd.concat([df, pd.Series(new_col_values, name=new_col_name)], axis=1)
            
            # if(not ForecastDataModel.is_valid_forecast_data_model(df_new)):
            #       raise ValueError(f"add_col_to_model:  Error, invalid forecast data model\n{df_new}")
            
            # return(df_new)


      # recalculate_forecast_df_model
      # Recalculate the fields that can be updated, especially after data transformations. 
      #  
      # INPUTS:
      #     DataFrame data
      # 
      # OUTPUTS:
      #     DataFrame df

      @staticmethod
      def recalculate_forecast_data_model_attributes(data: DataFrame) -> DataFrame:
            # make a shallow copy of df, may be revisited later      
            df = data.copy()

            # recalcuate whatever fields can be recalculated based on existing data
            # start_year
            df.attrs["start_year"] = ForecastDataModel.gen_start_year(df)  # start_year
            df.attrs["num_years"] = ForecastDataModel.gen_num_years(df)    # num_years
            df.attrs["start_month"] = ForecastDataModel.gen_start_month(df)    # start_month

            return(df)

            
      # is_valid_forecast_data_model
      # Runs a variety of checks to make sure this is a valid data forecast model 
      #  
      # INPUTS:
      #     DataFrame data - forecast model DataFrame to check
      # 
      # OUTPUTS:
      #     Tuple:
      #           bool is_valid - True if valid, False if not
      #           strg err_msg - descriptive error message of why the DataFrame is not valid, or "" if it is valid

      @staticmethod
      def is_valid_forecast_data_model(data: DataFrame) -> tuple[bool, str]:
            # check that it's the right class
            if(not isinstance(data, DataFrame)):
                   return(False, f"Not DataFrame, it is a '{type(data)}'")
            
            # Check that we have the "dates" column and it's the right type
            if(ForecastDataModel.RESERVED_COLUMN_INDEX_NAME not in data.columns):
                  return(False, f"Missing '{ForecastDataModel.RESERVED_COLUMN_INDEX_NAME}' in list of columns: {data.columns}.")
            
            if(data[ForecastDataModel.RESERVED_COLUMN_INDEX_NAME].dtype != np.dtype('datetime64[ns]')):
                  return(False, f"Incorrect type for '{ForecastDataModel.RESERVED_COLUMN_INDEX_NAME}', should be some equivalent of 'datetime64[ns]' but is actually '{data[ForecastDataModel.RESERVED_COLUMN_INDEX_NAME].dtype}'.")

            if(data.index.dtype != "int"):
                  return(False, f"Index should be some equivalent of 'int' but instead is '{data.index.dtype}'")
            
            # for each required attribute
            for i in range(len(ForecastDataModel.REQ_FORECAST_MODEL_ATTR_NAMES)):
                  # check that an attribute with that name exists in the pandas attributes dictionary
                  if(ForecastDataModel.REQ_FORECAST_MODEL_ATTR_NAMES[i] not in data.attrs):
                        return(False, f"That attribute '{ForecastDataModel.REQ_FORECAST_MODEL_ATTR_NAMES[i]}' not in the pandas.attrs of this DataFrame")
                  
                  # check that the attribute is the right type
                  if(not isinstance(data.attrs[ForecastDataModel.REQ_FORECAST_MODEL_ATTR_NAMES[i]], ForecastDataModel.REQ_FORECAST_MODEL_ATTR_TYPES[i])):
                        return(False, f"The attribute '{ForecastDataModel.REQ_FORECAST_MODEL_ATTR_NAMES[i]}' is of type '{type(data.attrs[ForecastDataModel.REQ_FORECAST_MODEL_ATTR_NAMES[i]])}', but is supposed to be of type '{ForecastDataModel.REQ_FORECAST_MODEL_ATTR_TYPES[i]}'")
                  
            return(True, "")

            
      # upsample_year_to_month
      # Convert a DateFrame set at a yearly frequency to one set at
      # a monthly frequency.  Divide all yearly values evenly across the months
      #  
      # INPUTS:
      #     DataFrame data
      # 
      # OUTPUTS:
      #   DataFrame df
      @staticmethod
      def upsample_yearly_to_monthly(data: DataFrame) -> DataFrame:
            df = data.copy()

            # if this is already a MONTHLY timescale then return it
            if(df.attrs["timescale"] == ForecastModelTimescale.MONTH):
                  return(df)
            
            # since all dates are YEAR-END, before we resample we have to add a new row with zero values and a date 
            # for the year-end before the earliest year-end date in the current dfset.
            # We do this, because, when resampling, pandas always stars with the earliest dates IN THE DATASET
            # and samples from there.  So if we have a YEAR-END date, we need it to create the 12 months PRIOR to the
            # first date... which means it needs an earlier date to start from (i.e. the previous year end date).
            # If we don't do this, pandas creates month end dates starting with our first year-end.
            # (someone who knows pandas better might have a better way to do this)

            df = ForecastDataModel.convert_to_working_index(df)

            # get the previous year end date, create a new row with all zeros and that date, and append to dfframe
            new_min_date = min(df.index) - pd.DateOffset(years=1)
            new_row = pd.DataFrame(data = [ForecastDataModel.EDITABLE_VALUES_TOKEN] * len(df.columns), index=pd.DatetimeIndex([new_min_date]))
            new_row.columns = df.columns
            new_row = DataFrame(data=new_row)
            df = pd.concat([df, new_row])
            
            # resample for ME, backfill all the NA values being generated with the annual number, and then divide by 12 (number months in a year)
            # this will spread the YEAR-END number evenly across all previous months in that year
            df = df.resample("ME").bfill().div(12)
            
            # finally get rid of the previous year end date (it's not part of the results, and it has a zero value in it)
            df = df.loc[df.index > min(df.index)]
            df.attrs["timescale"] = ForecastModelTimescale.MONTH

            df = ForecastDataModel.convert_to_counter_index(df)

            return(df)
      
      
      # downsample_monthly_to_yearly
      # Convert a ForecastDataModel set at a monthly frequency to one set at
      # a yearly frequency.  Sums all the monthly values at a yearly level
      # 
      # INPUTS:
      #   DataFrame set to 
      #
      # OUTPUTS:
      #   ForecastDataModel set to yearly frequency
      @staticmethod
      def downsample_monthly_to_yearly(data: DataFrame) -> DataFrame:
            # if this is already a YEARLY timescale then return it
            if(data.attrs["timescale"] == ForecastModelTimescale.YEAR):
                  return(data)
            
            df = ForecastDataModel.convert_to_working_index(data)

            end_of_month = df.attrs["start_month"]-1 if df.attrs["start_month"] != 1 else 12
            period = str("YE-"+ FORECAST_INT_TO_SHORT_MONTH_NAME[end_of_month])
            df = df.resample(period).sum()
            df.attrs["timescale"] = ForecastModelTimescale.YEAR

            df = ForecastDataModel.convert_to_counter_index(df)
            return(df)
    


      # combine_forecast_model
      # Takes a list of DataFrames and combines them into a single dataframe with a
      # total which is a sum of all the incoming ones.  Two rules which are applied:
      # 1. Timescale - If there are multiple timescale granualarities, always go for the greatest one (i.e. MONTHLY over YEARLY)
      # 2. 
      # 
      # INPUTS:
      #   List of ForecastDataModel
      #
      # OUTPUTS:
      #   ForecastDataModel
      @staticmethod
      def combine_forecast_models(datas: List[DataFrame], agg_col_funct="", agg_col_name="Total_", use_as_prefix=True) -> DataFrame:
            # if only one forecast model provided, return that one
            if(len(datas) == 1):
                  (is_valid, err_msg) = ForecastDataModel.is_valid_forecast_data_model(datas[0])

                  if(not is_valid):
                        raise ValueError(f"Unable to combine forecast models.  In the list of inputs, #1 is not a valid forecast model: {err_msg}")
                  
                  return(datas[0])
            
            # if multiple forecast models, do the following:

            # initialize a bunch of variables which will track if all the forecast parameters of
            # the data sets align (same: start_year, num_years, input_types, etc.)
            # In the current version, if they don't all align, we throw an error (not try to fix)
            multiple_start_year = False
            multiple_num_year = False
            multiple_input_type = False
            multiple_start_month = False
            multiple_timescale = False

            # As we iterate through the data sets validating, we will also grab a copy of the "Totals" cols from each 
            # DataFrames being combined.  This will allow us to run an (optional) agg function later (agg_col_funct) 
            # to create a new Total row for all of them.  The variable initialized below will hold those "Totals" cols
            df_all_totals_col = pd.DataFrame()

            # Create copies of all the input data sets
            dfs = datas.copy()

            # run the validation loop against all data sets to ensure that
            # they all match the initial data sets input parameters (this does end up running the first)
            # dataset against its own parameters, which will ALWAYS be a match, but necessary copy the totals column, so kept
            for i in range(len(dfs)):
                 # Before checking the input parameters, check that the current data set is a valid Forecasting Model
                 (is_valid, err_msg) = ForecastDataModel.is_valid_forecast_data_model(dfs[i])

                 if(is_valid == False):
                       raise ValueError(f"Unable to combine forecast models.  In the list of inputs, #{i+1} is not a valid forecast model: {err_msg}")
                 
                 # in the first loop, take the forecast parameters from the first data set which will be compared to
                 # by all subsequent data sets
                 if(i == 0):
                       start_year = dfs[0].attrs["start_year"]
                       num_years = dfs[0].attrs["num_years"]
                       input_type = dfs[0].attrs["input_type"]
                       start_month = dfs[0].attrs["start_month"]
                       timescale = dfs[0].attrs["timescale"]
                  
                  # if any of required forecast parameters DON'T match the previous loops parameters, flag an
                  # error for which parameter doesn't match.  At the end, we will return an error message
                  # for all flags which show true
                 else:
                       if(dfs[i].attrs["start_year"] != start_year):
                             multiple_start_year = True
                             
                       if(dfs[i].attrs["num_years"] != num_years):
                             multiple_num_year = True

                       if(dfs[i].attrs["input_type"] != input_type):
                             multiple_input_type = True

                       if(dfs[i].attrs["start_month"] != start_month):
                             multiple_start_month = True

                       if(dfs[i].attrs["timescale"] != timescale):
                             multiple_timescale = True
                             
                 # grab the last rightmost column (defined as the totals column) and put in a common dataframe
                 df_temp = ForecastDataModel.convert_to_working_index(dfs[i])

                 if(i == 0):
                       df_all_totals_col = df_temp[df_temp.columns[-1]]
                 else:
                       df_all_totals_col = pd.concat([df_all_totals_col, df_temp[df_temp.columns[-1]]], axis=1)


            # Check if there are any issues with multiples.  If any of the key attributes of the forecast don't match, then
            # raise an error
            errMsg = ""

            if(multiple_start_year):
                  errMsg += f"\nDifferent values for {ForecastDataModel.REQ_FORECAST_MODEL_ATTR_DISPLAY_NAMES[0]}."

            if(multiple_num_year):
                  errMsg += f"\nDifferent values for {ForecastDataModel.REQ_FORECAST_MODEL_ATTR_DISPLAY_NAMES[1]}."
                              
            if(multiple_input_type):
                  errMsg += f"\nDifferent values for {ForecastDataModel.REQ_FORECAST_MODEL_ATTR_DISPLAY_NAMES[2]}."
                              
            if(multiple_start_month):
                  errMsg += f"\nDifferent values for {ForecastDataModel.REQ_FORECAST_MODEL_ATTR_DISPLAY_NAMES[3]}."
                              
            if(multiple_timescale):
                  errMsg += f"\nDifferent values for {ForecastDataModel.REQ_FORECAST_MODEL_ATTR_DISPLAY_NAMES[4]}."

            if(errMsg != ""):
                  raise ValueError(f"Error merging multiple Forecast Models: {errMsg}")
         
            # if everything is valid, we can (finally) combine the dataframes
            dfs_out = [ForecastDataModel.convert_to_working_index(df) for df in dfs]
            combined_pd = pd.concat(dfs_out, axis=1)
            combined_pd = ForecastDataModel.convert_to_counter_index(combined_pd)

            # run an (optional) aggregation function on all the "Total" columns of the Forcast Data Models provided
            # (defined as the rightmost column in each of the DataFrames)
            if(agg_col_funct != ""):
                  if(agg_col_name == ""):
                        raise ValueError(f"Agg_col_funct '{agg_col_funct}' provided, but invalid agg_call_name '{agg_col_name}'.")
                  
                  match agg_col_funct:
                        case "sum":
                              df_new_agg_col = df_all_totals_col.sum(axis=1)
                        case _:
                              raise ValueError(f"Invalid aggregation function called when merging multiple Forecast Models: {agg_col_funct}")
                        
                  # set-up the agg_col_name, if it's to be used as a prefix, generate a unique name by combining all the totals column names
                  # and separating with a "-"
                  if(use_as_prefix):
                        agg_col_name = str(agg_col_name + "-".join(df_all_totals_col.columns))
                  
                  # before adding the column to the end, need to convert it into a DataFrame with the correct Forecast Build Model, so that the concat won't wipe this out
                  df_new_agg_col = DataFrame(data=df_new_agg_col.to_frame(name=agg_col_name).reset_index(drop=False, names=[ForecastDataModel.RESERVED_COLUMN_INDEX_NAME]))
                  df_new_agg_col = ForecastDataModel.init_forecast_data_model(df_new_agg_col,
                                                                              start_year = combined_pd.attrs["start_year"],
                                                                              num_years = combined_pd.attrs["num_years"],
                                                                              input_type = combined_pd.attrs["input_type"],
                                                                              start_month = combined_pd.attrs["start_month"],
                                                                              timescale = combined_pd.attrs["timescale"])
                  #combined_pd = ForecastDataModel.convert_to_working_index(combined_pd)
                  #df_new_agg_col = ForecastDataModel.convert_to_working_index(df_new_agg_col)

                  agg_pd = pd.concat([ForecastDataModel.convert_to_working_index(combined_pd),
                                           ForecastDataModel.convert_to_working_index(df_new_agg_col)], axis=1)

                  agg_pd = ForecastDataModel.convert_to_counter_index(agg_pd)

                  # validate that this is a legitimate forecast
                  (is_valid, err_msg) = ForecastDataModel.is_valid_forecast_data_model(agg_pd)

                  if(not is_valid):
                        raise ValueError(f"Error merging multiple Forecast Models.  Resulting model is not a valid forecast model: {err_msg}")
            
                  return(agg_pd)
            else:
                  # validate that this is a legitimate forecast
                  (is_valid, err_msg) = ForecastDataModel.is_valid_forecast_data_model(combined_pd)

                  if(not is_valid):
                        raise ValueError(f"Error merging multiple Forecast Models.  Resulting model is not a valid forecast model: {err_msg}")
            
                  return(combined_pd)




      # update_shared_vars
      # Take all the forecast variables in the dataframe and put it in the shared context provided by the calling object.
      # This is used to updated the flow/graph level shared variables which components use
      #  
      # INPUTS:
      # None
      # 
      # OUTPUTS:
      # None
      @staticmethod
      def update_shared_vars(ctx, df):
            for field_name in ForecastDataModel.REQ_FORECAST_MODEL_ATTR_NAMES:
                  ctx[field_name] = df.attrs[field_name]


      # HELPER FUNCTIONS
      # ================
      
      # gen_forecast_dates
      # Creates a series of dates which or compatible with the Forecast Data Model given all the standard inputs.  Added this function
      # to centralize date creation in this static class
      #  
      # INPUTS:
      #     start_year - the start year for the forecast
      #     num_years - number of years for the forecast
      #     start_month - the month of the start of a fiscal year
      #     timescale - wether to each date covers a year or a month 
      # 
      # OUTPUTS:
      #   List of pd.Timestamps with the correct dates for the requested Forecast Data model

      @staticmethod
      def gen_forecast_dates(
            start_year: int, 
            num_years: int, 
            start_month: int=1, 
            timescale: ForecastModelTimescale = ForecastModelTimescale.YEAR,
      ) -> List[pd.Timestamp]:
            return(gen_dates(start_year=start_year, num_years=num_years, start_month=start_month, time_scale=timescale))


      # fix_index_issues
      # Validates that we have a plain old counting index and a 'dates' field with the pd.DateTimeIndex.  If not, tries a
      # variety of different things to fix it, and if successful, results the fixed DataFrame.  If not, raises an error
      #  
      # INPUTS:
      #     df_out - A DataFrame to check
      # 
      # OUTPUTS:
      #   df_out - A DataFrame is either fixed, or was fine to begin with

      @staticmethod
      def fix_index_issues(data: DataFrame) -> DataFrame:
            df = data.copy()

            # Check if there's a "dates" column
            if(ForecastDataModel.RESERVED_COLUMN_INDEX_NAME in df.columns):

                  # if there is, make sure or fix the type to be datetime64[ns]
                  if(df[ForecastDataModel.RESERVED_COLUMN_INDEX_NAME].dtype != np.dtype('datetime64[ns]')):
                        df[ForecastDataModel.RESERVED_COLUMN_INDEX_NAME] = pd.to_datetime(df[ForecastDataModel.RESERVED_COLUMN_INDEX_NAME])

                  # if we have the "dates" column, then make sure our index is a regular counting index
                  df = df.reset_index(drop=True)

            # if we don't have a "dates" column, then check if the index is already a dates column, if it is, move it back to dates and then reset the index
            elif(df[df.index].dtype == np.dtype('datetime64[ns]')):
                  df = df.reset_index()
                  df = df.rename(columns={'index': ForecastDataModel.RESERVED_COLUMN_INDEX_NAME})

            # if all else fails, attempt to convert first the index to datetime, if it succeeds, move back to dates and then reset, if not, raise a ValueError
            else:
                  try:
                        df[ForecastDataModel.RESERVED_COLUMN_INDEX_NAME] = pd.to_datetime(df.index)

                        # if it succeeded, reset the index
                        df = df.reset_index(drop=True)
                  except (ValueError, ParserError) as errMsg:
                        raise ValueError(f"Missing or invalid '{ForecastDataModel.RESERVED_COLUMN_INDEX_NAME}': {errMsg}")
                  
            return(df)


      # convert_to_working_index
      # Takes the "counter" index and turns it into a pd.DatetimeIndex for doing "work" (process which requires date manipulation)
      # using the RESERVED_COLUMN_INDEX_NAME
      #  
      # INPUTS:
      #     df - A DataFrame to check
      # 
      # OUTPUTS:
      #   df - DataFrame with an index that is pd.Datetimeindex and NO RESERVED_COLUMN_INDEX_NAME column
      @staticmethod
      def convert_to_working_index(data: DataFrame) -> DataFrame:
            df = data.copy()

            df.set_index(ForecastDataModel.RESERVED_COLUMN_INDEX_NAME, inplace=True)
            return(df)


      # convert_to_counter_index
      # Takes the "working" (pd.DatetimeIndex) index and turns it back to a counter index, and puts the pd.DatetimeIndex back
      # in a 'dates' colum (i.e. RESERVED_COLUMN_INDEX_NAME)
      #  
      # INPUTS:
      #     df - DataFrame with an index that is pd.Datetimeindex and NO RESERVED_COLUMN_INDEX_NAME column
      # 
      # OUTPUTS:
      #   df_out - DataFrame with a "counter" index and a RESERVED_COLUMN_INDEX_NAME column which is type pd.Datetimeindex
      @staticmethod
      def convert_to_counter_index(data: DataFrame) -> DataFrame:
            df = data.copy()

            df.reset_index(inplace=True)
            df = df.rename(columns={'index': ForecastDataModel.RESERVED_COLUMN_INDEX_NAME})
            return(df)


      # start_year
      @staticmethod
      def gen_start_year(df: DataFrame) -> int:
            # since these are all end of timescale periods, need to subtract one timeperiod from the earliest date
            if(df.attrs["timescale"] == ForecastModelTimescale.MONTH):
                  timedelta = pd.DateOffset(month=1)
            else:
                  timedelta = pd.DateOffset(years=1)
            
            # figure out start_year
            start_year = (min(df[ForecastDataModel.RESERVED_COLUMN_INDEX_NAME]) - timedelta).year
            return(start_year)
      
      
      # gen_num_years
      @staticmethod
      def gen_num_years(df: DataFrame) -> int:
            # figure out the num_years
            num_years = max(df[ForecastDataModel.RESERVED_COLUMN_INDEX_NAME]).year - min(df[ForecastDataModel.RESERVED_COLUMN_INDEX_NAME]).year + 1
            return(num_years)
      

      # gen_start_month
      @staticmethod
      def gen_start_month(df: DataFrame) -> int:
            # figure out the start_month
            start_month = min(df[ForecastDataModel.RESERVED_COLUMN_INDEX_NAME]).month + 1
            return(start_month)